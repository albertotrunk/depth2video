{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMzWu/P9R2LvZ7NLvUMJ50g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertotrunk/depth2video/blob/main/02_inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR0-DVxb3W47"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade git+https://github.com/huggingface/diffusers.git transformers accelerate scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionInpaintPipeline\n",
        "\n",
        "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
        "    torch_dtype=torch.float16,\n",
        ").to(\"cuda\")"
      ],
      "metadata": {
        "id": "YJsFIxJCQEx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "from torchvision.transforms import GaussianBlur\n",
        "\n",
        "url_mask = \"https://raw.githubusercontent.com/albertotrunk/depth2video/main/example/depth.png?raw=true\" #@param {type:\"string\"}\n",
        "mask_image = Image.open(requests.get(url_mask, stream=True).raw).convert('RGB')\n",
        "\n",
        "\n",
        "mask_image = mask_image.convert('L')\n",
        "\n",
        "mask = np.array(mask_image)\n",
        "\n",
        "strength = 1  # this controls the \"strength\" of the prompt relative to the init image\n",
        "\n",
        "d = int(255 * (1-strength))\n",
        "mask *= 255-d # convert from range [0,1] to [0,255]\n",
        "mask += d\n",
        "\n",
        "mask_image = Image.fromarray(mask)\n",
        "\n",
        "display(mask_image)\n",
        "\n",
        "# fuzzing the mask edges generally improves synthesis results\n",
        "\n",
        "blur = GaussianBlur(11,20)\n",
        "mask_image = blur(mask_image)\n",
        "\n",
        "\n",
        "url_init = \"https://raw.githubusercontent.com/albertotrunk/depth2video/main/example/color.png?raw=true\" #@param {type:\"string\"}\n",
        "init_image = Image.open(requests.get(url_init, stream=True).raw)\n",
        "display(init_image)\n"
      ],
      "metadata": {
        "id": "hZcWSRS899yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image and mask_image should be PIL images.\n",
        "#The mask structure is white for inpainting and black for keeping as is\n",
        "prompt = \"a photo of Scarlett Johansson with a short haircut wearing a white sweater, hyper resolution 10k\" #@param {type:\"string\"}\n",
        "negative_prompt = \"border, frame, lowres, jpeg artifacts, low quality, normal quality, worst quality, poorly drawn, error. abstract, asymmetrical, blurry, cropped, disconnected, duplicate, extra, missing, signature, text, username, watermark. amputee, bad anatomy, deformed, disfigured, disproportionate, eye bags, fused, malformed, morbid, mutated, mutation, mutilated, hands, fingers,bad hand,extra limbs,missing limb,extra leg,missing leg,missing hand,extra hand\"  #@param {type:\"string\"}\n",
        "\n",
        "guidance_scale = 5  #@param {type:\"number\"}\n",
        "\n",
        "image = pipe(prompt=prompt, negative_prompt=negative_prompt, guidance_scale=guidance_scale, image=init_image, mask_image=mask_image).images[0]\n",
        "image"
      ],
      "metadata": {
        "id": "L4y0LgZx90Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "images = [init_image,mask_image,image]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "columns = 3\n",
        "for i, image in enumerate(images):\n",
        "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
        "    plt.imshow(image)"
      ],
      "metadata": {
        "id": "m6EBD0yrHQnr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
