{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertotrunk/depth2video/blob/main/stable_diffusion_depth2video_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites\n"
      ],
      "metadata": {
        "id": "O0YPN0wHlgiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#todo\n",
        "#ffmpeg -start_number 0 -i input.%03d.png -c:v libx264 -r 24 -pix_fmt yuv420p output.mp4\n",
        "#ffmpeg -i output.mp4 -filter:v \"minterpolate=mi_mode=2\" output.mp4 \n",
        "#ffmpeg -i <input> -filter:v fps=30 <output>\n",
        "#sampledata\n",
        "#color.mp4\n",
        "#depth\n",
        "\n",
        "#GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "\n",
        "#memory\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "lBKzEnqcuVxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hZumUlQICuv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365cddb6-51e3-432b-aa7d-258ddba317d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-lh0_xl63\n",
            "  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-lh0_xl63\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 28.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 97.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.26.0.dev0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.26.0.dev0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (3.0.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.26.0.dev0-py3-none-any.whl size=5961994 sha256=859c018af991ba8d6531e290ede15579afef16de005896ad3cf2fa91c4ff0468\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f0_7c_ek/wheels/05/0a/97/64ae47c27ba95fae2cb5838e7b4b7247a34d4a8ba5f7092de2\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.26.0.dev0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/diffusers.git\n",
            "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-gqt69kf3\n",
            "  Running command git clone -q https://github.com/huggingface/diffusers.git /tmp/pip-req-build-gqt69kf3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.15.0-py3-none-any.whl (191 kB)\n",
            "\u001b[K     |████████████████████████████████| 191 kB 30.5 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 33.8 MB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from diffusers==0.10.2) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from diffusers==0.10.2) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from diffusers==0.10.2) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from diffusers==0.10.2) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from diffusers==0.10.2) (3.8.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from diffusers==0.10.2) (7.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from diffusers==0.10.2) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.10.2) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.10.2) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.10.2) (4.4.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.10.2) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub>=0.10.0->diffusers==0.10.2) (3.0.9)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.13.0+cu116)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->diffusers==0.10.2) (3.11.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers==0.10.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers==0.10.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers==0.10.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers==0.10.2) (2022.9.24)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.10.2-py3-none-any.whl size=511543 sha256=a868405a164c3e93ea383688612d87c9c0ff0fff04237b4f5f7a98787e0db9a3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hu535_p1/wheels/28/16/cf/d8d37579fd1e7edb978252d850ec9328b055a7582ddfae3b87\n",
            "Successfully built diffusers\n",
            "Installing collected packages: scipy, ftfy, diffusers, accelerate\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "Successfully installed accelerate-0.15.0 diffusers-0.10.2 ftfy-6.1.1 scipy-1.9.3\n"
          ]
        }
      ],
      "source": [
        "#%pip install ..\n",
        "\n",
        "%pip install -U git+https://github.com/huggingface/transformers.git\n",
        "%pip install -U git+https://github.com/huggingface/diffusers.git accelerate ftfy scipy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt5s_yLzCuv8"
      },
      "source": [
        "# Basic img2depth\n",
        "Main example img2depth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import requests\n",
        "from PIL import Image\n",
        "from diffusers import StableDiffusionDepth2ImgPipeline\n",
        "\n",
        "pipe = StableDiffusionDepth2ImgPipeline.from_pretrained(\n",
        "   \"stabilityai/stable-diffusion-2-depth\",\n",
        "   torch_dtype=torch.float16,\n",
        ").to(\"cuda\")\n",
        "\n",
        "init_image = \"https://user-images.githubusercontent.com/8300565/207172663-d347b44f-bce3-4a15-9e92-5411ccdd7cb4.png\" #@param {type:\"string\"}\n",
        "init_image = Image.open(requests.get(init_image, stream=True).raw)\n",
        "\n",
        "init_image\n",
        "\n",
        "prompt = \"scarlett johansson\" #@param {type:\"string\"}\n",
        "n_propmt = \"bad, deformed, ugly, bad anotomy\" #@param {type:\"string\"}\n",
        "strength = 0.2  #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "image = pipe(prompt=prompt, image=init_image, negative_prompt=n_propmt, strength=strength).images[0]\n",
        "\n",
        "image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "V6Teta2iiWf4",
        "outputId": "706d9e60-a593-4268-b5a6-116053c9e2b2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0d53bcca7a81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://user-images.githubusercontent.com/8300565/207172663-d347b44f-bce3-4a15-9e92-5411ccdd7cb4.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-0d53bcca7a81>\u001b[0m in \u001b[0;36mshow_image\u001b[0;34m(path_to_image, width, height)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown extension: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mdata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data:image/jpeg;base64,'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://user-images.githubusercontent.com/8300565/207172663-d347b44f-bce3-4a15-9e92-5411ccdd7cb4.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkdNb3v9CuwA"
      },
      "outputs": [],
      "source": [
        "# the object returned is a python generator\n",
        "answers = stability_api.generate(\n",
        "    prompt=\"houston, we are a 'go' for launch!\",\n",
        "    seed=34567, # if provided, specifying a random seed makes results deterministic\n",
        "    steps=20, # defaults to 30 if not specified\n",
        ")\n",
        "\n",
        "# iterating over the generator produces the api response\n",
        "for resp in answers:\n",
        "    for artifact in resp.artifacts:\n",
        "        if artifact.finish_reason == generation.FILTER:\n",
        "            warnings.warn(\n",
        "                \"Your request activated the API's safety filters and could not be processed.\"\n",
        "                \"Please modify the prompt and try again.\")\n",
        "        if artifact.type == generation.ARTIFACT_IMAGE:\n",
        "            img = Image.open('/content/sample_data/01_c.png')\n",
        "            display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxbTcxbhCuwB"
      },
      "source": [
        "# Intermediate usage\n",
        "\n",
        "3. (new!) An \"init\" image can be provided for text-driven image modification. To demonstrate, we can convert the image we just generated to a colored pencil sketch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9Ld7yyQCuwC"
      },
      "outputs": [],
      "source": [
        "answers = stability_api.generate(\n",
        "    prompt=\"childrens crayon drawing of a rocket launch\",\n",
        "    init_image=img,\n",
        "    seed=54321, # if we're passing in an image generated by SD, you may get better results by providing a different seed value than was used to generate the image\n",
        "    start_schedule=0.6, # this controls the \"strength\" of the prompt relative to the init image\n",
        ")\n",
        "\n",
        "# iterating over the generator produces the api response\n",
        "for resp in answers:\n",
        "    for artifact in resp.artifacts:\n",
        "        if artifact.finish_reason == generation.FILTER:\n",
        "            warnings.warn(\n",
        "                \"Your request activated the API's safety filters and could not be processed.\"\n",
        "                \"Please modify the prompt and try again.\")\n",
        "        if artifact.type == generation.ARTIFACT_IMAGE:\n",
        "            img2 = img\n",
        "            display(img2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQyTnMbKCuwC"
      },
      "outputs": [],
      "source": [
        "# we can make a rough mask by thresholding the grayscaled image\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "img2_grayscale = Image.open('/content/sample_data/01_m.png').convert('L')\n",
        "img2_a = np.array(img2_grayscale)\n",
        "\n",
        "mask = np.array(img2_grayscale)\n",
        "strength = .2  # this controls the \"strength\" of the prompt relative to the init image\n",
        "\n",
        "d = int(255 * (1-strength))\n",
        "mask *= 255-d # convert from range [0,1] to [0,255]\n",
        "mask += d\n",
        "\n",
        "mask = Image.fromarray(mask)\n",
        "mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97E6HeL3CuwD"
      },
      "outputs": [],
      "source": [
        "# fuzzing the mask edges generally improves synthesis results\n",
        "\n",
        "from torchvision.transforms import GaussianBlur\n",
        "\n",
        "blur = GaussianBlur(11,20)\n",
        "mask = blur(mask)\n",
        "mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiEtrDHNCuwD"
      },
      "outputs": [],
      "source": [
        "# now, let's send our drawing into space\n",
        "answers = stability_api.generate(\n",
        "    prompt=\"scarlett johansson\",\n",
        "    init_image=img2,\n",
        "    mask_image=mask,\n",
        "    seed=12345, # if we're passing in an image generated by SD, you may get better results by providing a different seed value than was used to generate the image\n",
        "    start_schedule=1,\n",
        ")\n",
        "\n",
        "for resp in answers:\n",
        "    for artifact in resp.artifacts:\n",
        "        if artifact.finish_reason == generation.FILTER:\n",
        "            warnings.warn(\n",
        "                \"Your request activated the API's safety filters and could not be processed.\"\n",
        "                \"Please modify the prompt and try again.\")\n",
        "        if artifact.type == generation.ARTIFACT_IMAGE:\n",
        "            img3 = Image.open(io.BytesIO(artifact.binary))\n",
        "            display(img3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUz_eBrQCuwD"
      },
      "outputs": [],
      "source": [
        "# we can improve our image result by introducing clip guidance into the request. this takes longer (and costs more compute) but often yields better results.\n",
        "# clip guidance is built with several presets optimized for speed or quality, but clip can be controlled more precisely with a variety of other params\n",
        "\n",
        "answers = stability_api.generate(\n",
        "    prompt=\"houston, we are a 'go' for launch!\",\n",
        "    seed=34567,  \n",
        "    steps=35, # minimum of 35 steps recommended when using CLIP\n",
        "    guidance_preset = generation.GUIDANCE_PRESET_FAST_BLUE\n",
        ")\n",
        "\n",
        "for resp in answers:\n",
        "    for artifact in resp.artifacts:\n",
        "        if artifact.finish_reason == generation.FILTER:\n",
        "            warnings.warn(\n",
        "                \"Your request activated the API's safety filters and could not be processed.\"\n",
        "                \"Please modify the prompt and try again.\")\n",
        "        if artifact.type == generation.ARTIFACT_IMAGE:\n",
        "            img4 = Image.open(io.BytesIO(artifact.binary))\n",
        "            print('GUIDANCE: FAST-BLUE:')\n",
        "            display(img4)\n",
        "\n",
        "answers = stability_api.generate(\n",
        "    prompt=\"houston, we are a 'go' for launch!\",\n",
        "    seed=34567, \n",
        "    steps=35, \n",
        "    guidance_preset = generation.GUIDANCE_PRESET_SLOWER\n",
        ")\n",
        "\n",
        "for resp in answers:\n",
        "    for artifact in resp.artifacts:\n",
        "        if artifact.finish_reason == generation.FILTER:\n",
        "            warnings.warn(\n",
        "                \"Your request activated the API's safety filters and could not be processed.\"\n",
        "                \"Please modify the prompt and try again.\")\n",
        "        if artifact.type == generation.ARTIFACT_IMAGE:\n",
        "            img5 = Image.open(io.BytesIO(artifact.binary))\n",
        "            print('GUIDANCE: SLOWER:')\n",
        "            display(img5)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 ('dmarx-je5LfYh2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "57881a85d677a34ea29564e0084ef84f4058c4e30a2bb466eb0e0b908d0628df"
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}