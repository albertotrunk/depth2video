{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPBa2+XweQtjZYft0avdo7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertotrunk/depth2video/blob/main/03_img2img.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR0-DVxb3W47"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade git+https://github.com/huggingface/diffusers.git transformers accelerate scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "\n",
        "# load the pipeline\n",
        "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
        "\n",
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        ").to(\"cuda\")\n",
        "\n"
      ],
      "metadata": {
        "id": "csK85InMEEZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "from torchvision.transforms import GaussianBlur\n",
        "\n",
        "url_mask = \"https://raw.githubusercontent.com/albertotrunk/depth2video/main/example/depth.png?raw=true\" #@param {type:\"string\"}\n",
        "mask_image = Image.open(requests.get(url_mask, stream=True).raw).convert('RGB')\n",
        "display(mask_image)\n",
        "\n",
        "url_init = \"https://raw.githubusercontent.com/albertotrunk/depth2video/main/example/color.png?raw=true\" #@param {type:\"string\"}\n",
        "init_image = Image.open(requests.get(url_init, stream=True).raw).convert('RGB')\n",
        "display(init_image)\n",
        "\n",
        "\n",
        "src = np.array(init_image)\n",
        "mask = np.array(mask_image)\n",
        "\n",
        "print(mask.dtype, mask.min(), mask.max())\n",
        "# uint8 0 255\n",
        "\n",
        "mask = mask / 255\n",
        "\n",
        "print(mask.dtype, mask.min(), mask.max())\n",
        "# float64 0.0 1.0\n",
        "\n",
        "dst = src * mask\n",
        "\n",
        "masked_img = Image.fromarray(dst.astype(np.uint8))\n",
        "masked_img"
      ],
      "metadata": {
        "id": "ozr5wbwvI2NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#image and mask_image should be PIL images.\n",
        "#The mask structure is white for inpainting and black for keeping as is\n",
        "prompt = \"a photo of Scarlett Johansson with a short haircut wearing a white sweater, hyper resolution 10k\" #@param {type:\"string\"}\n",
        "negative_prompt = \"border, frame, lowres, jpeg artifacts, low quality, normal quality, worst quality, poorly drawn, error. abstract, asymmetrical, blurry, cropped, disconnected, duplicate, extra, missing, signature, text, username, watermark. amputee, bad anatomy, deformed, disfigured, disproportionate, eye bags, fused, malformed, morbid, mutated, mutation, mutilated, hands, fingers,bad hand,extra limbs,missing limb,extra leg,missing leg,missing hand,extra hand\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "images = pipe(prompt=prompt, image=masked_img, strength=0.41, guidance_scale=9.5, negative_prompt=negative_prompt).images\n",
        "\n",
        "image = images[0]\n",
        "image"
      ],
      "metadata": {
        "id": "36gPc-qqDnzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "images = [init_image,mask_image,masked_img,image]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "columns = 4\n",
        "for i, image in enumerate(images):\n",
        "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
        "    plt.imshow(image)"
      ],
      "metadata": {
        "id": "XmYw3t4uWdtk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}